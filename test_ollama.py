#!/usr/bin/env python3

"""
Test script to verify Ollama configuration
"""

import os
from decouple import config

def test_ollama_config():
    """Test Ollama configuration"""
    print("ğŸ§ª Testing Ollama Configuration")
    print("=" * 40)
    
    # Test environment variables
    use_ollama = config('USE_OLLAMA', default=False, cast=bool)
    
    if use_ollama:
        ollama_model = config('OLLAMA_MODEL', default='llama2')
        ollama_base_url = config('OLLAMA_BASE_URL', default='http://localhost:11434')
        
        print(f"âœ… USE_OLLAMA: {use_ollama}")
        print(f"âœ… OLLAMA_MODEL: {ollama_model}")
        print(f"âœ… OLLAMA_BASE_URL: {ollama_base_url}")
        
        # Test connection
        import requests
        try:
            response = requests.get(f"{ollama_base_url}/api/tags", timeout=5)
            if response.status_code == 200:
                models = response.json().get('models', [])
                print(f"âœ… Ollama connection successful")
                print(f"ğŸ“‹ Available models: {len(models)}")
                for model in models:
                    print(f"   - {model.get('name', 'Unknown')}")
                
                # Check if configured model is available
                model_names = [m.get('name', '') for m in models]
                if any(ollama_model in name for name in model_names):
                    print(f"âœ… Configured model '{ollama_model}' is available")
                else:
                    print(f"âš ï¸ Configured model '{ollama_model}' not found")
                    print(f"ğŸ’¡ Run: ollama pull {ollama_model}")
            else:
                print(f"âŒ Ollama connection failed: HTTP {response.status_code}")
        except requests.exceptions.RequestException as e:
            print(f"âŒ Cannot connect to Ollama: {e}")
            print("ğŸ’¡ Make sure Ollama is running: ollama serve")
    else:
        # Test OpenAI configuration
        openai_key = config('OPENAI_API_KEY', default=None)
        if openai_key:
            print(f"âœ… OpenAI API key configured")
            print(f"ğŸ”‘ Key length: {len(openai_key)} characters")
        else:
            print("âŒ No AI model configured")
            print("ğŸ’¡ Set either OPENAI_API_KEY or USE_OLLAMA=true in .env")

def test_qa_crew_import():
    """Test QA Crew import"""
    print("\nğŸ§ª Testing QA Crew Import")
    print("=" * 40)
    
    try:
        from qa_crew import QACrew
        print("âœ… QA Crew import successful")
        
        # Test agent creation
        crew = QACrew()
        print(f"âœ… QA Crew initialized with {len(crew.agents)} agents")
        
        agent_names = list(crew.agents.keys())
        print(f"ğŸ‘¥ Agents: {', '.join(agent_names)}")
        
    except Exception as e:
        print(f"âŒ QA Crew import failed: {e}")

if __name__ == "__main__":
    test_ollama_config()
    test_qa_crew_import()
    
    print("\nğŸ¯ Next Steps:")
    print("1. If using Ollama: ollama serve")
    print("2. Test analysis: python qa_cli.py --crew")
    print("3. See OLLAMA_SETUP.md for detailed setup") 